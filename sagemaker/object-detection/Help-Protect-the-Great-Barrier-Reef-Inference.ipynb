{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb34820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.predictor import json_serializer, json_deserializer, Predictor\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(service_name=\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb64c0",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Now that the trained model is deployed at an endpoint that is up-and-running, we can use this endpoint for inference. The results of a call to the inference endpoint are in a format that is similar to the .lst format, with the addition of a confidence score for each detected object. The format of the output can be represented as `[class_index, confidence_score, xmin, ymin, xmax, ymax]`. Typically, we don't visualize low-confidence predictions.\n",
    "\n",
    "\n",
    "We have provided a script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "    \"\"\"\n",
    "    visualize detections in one image\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img : numpy.array\n",
    "        image, in bgr format\n",
    "    dets : numpy.array\n",
    "        ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "        each row is one object\n",
    "    classes : tuple or list of str\n",
    "        class names\n",
    "    thresh : float\n",
    "        score threshold\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "\n",
    "    img = mpimg.imread(img_file)\n",
    "    plt.imshow(img)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    colors = dict()\n",
    "    num_detections = 0\n",
    "    for det in dets:\n",
    "        (klass, score, x0, y0, x1, y1) = det\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        num_detections += 1\n",
    "        cls_id = int(klass)\n",
    "        if cls_id not in colors:\n",
    "            colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "        xmin = int(x0 * width)\n",
    "        ymin = int(y0 * height)\n",
    "        xmax = int(x1 * width)\n",
    "        ymax = int(y1 * height)\n",
    "        rect = plt.Rectangle(\n",
    "            (xmin, ymin),\n",
    "            xmax - xmin,\n",
    "            ymax - ymin,\n",
    "            fill=False,\n",
    "            edgecolor=colors[cls_id],\n",
    "            linewidth=3.5,\n",
    "        )\n",
    "        plt.gca().add_patch(rect)\n",
    "        class_name = str(cls_id)\n",
    "        if classes and len(classes) > cls_id:\n",
    "            class_name = classes[cls_id]\n",
    "        print(\"{},{}\".format(class_name, score))\n",
    "        plt.gca().text(\n",
    "            xmin,\n",
    "            ymin - 2,\n",
    "            \"{:s} {:.3f}\".format(class_name, score),\n",
    "            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "            fontsize=12,\n",
    "            color=\"white\",\n",
    "        )\n",
    "\n",
    "    print(\"Number of detections: \" + str(num_detections))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e32fc",
   "metadata": {},
   "source": [
    "Now we use our endpoint to try to detect objects within an image. Since the image is a jpeg, we use the appropriate content_type to run the prediction. The endpoint returns a JSON object that we can simply load and peek into. We have packaged the prediction code into a function to make it easier to test other images. Note that we are defaulting the confidence threshold to 30% in our example, as a couple of the birds in our sample images were not being detected as clearly. Defining an appropriate threshold is entirely dependent on your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0175120",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'object-detection-2021-11-24-22-39-23-367'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5851847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_starfish_prediction(filename, ep, thresh=0.20):\n",
    "    b = \"\"\n",
    "    with open(filename, \"rb\") as image:\n",
    "        f = image.read()\n",
    "        b = bytearray(f)\n",
    "    endpoint_response = runtime.invoke_endpoint(EndpointName=ep, ContentType=\"image/jpeg\", Body=b)\n",
    "    results = endpoint_response[\"Body\"].read()\n",
    "    detections = json.loads(results)\n",
    "#     return detections\n",
    "    visualize_detection(filename, detections[\"prediction\"], ['starfish'], thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O starfish.jpg https://upload.wikimedia.org/wikipedia/commons/8/8f/CrownofThornsStarfish_Fiji_2005-10-12.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffcf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    show_starfish_prediction(\"starfish.jpg\", endpoint_name)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cf4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_starfish_prediction(\"starfish.png\", endpoint_name)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b56e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
